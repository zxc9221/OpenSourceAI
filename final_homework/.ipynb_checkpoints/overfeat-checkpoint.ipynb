{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "alG4BtsIpdWG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from mnist_local_generator import mnist_localization_generator\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from utils import xywh2xyxy, draw_rectangle\n",
    "import cv2\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6ugar1RZpo2U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배경 class가 포함되어 class 는 11로 설정 되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 39997.94it/s]\n",
      "  4%|▍         | 40/1000 [00:00<00:02, 395.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image 을 random 하게 resize 합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 459.96it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 49992.30it/s]\n",
      "  5%|▌         | 50/1000 [00:00<00:01, 495.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image 을 random 하게 resize 합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 462.31it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object 가 없는 background 이미지를 추가합니다.(전체 이미지의 10%)\n",
      "background 의 class 는 11로 설정 되어 있습니다.\n",
      "background 의 regression 는 (0,0,0,0)로 설정 되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 416.70it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 460.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 231, 231, 1) (1100, 231, 231, 1)\n"
     ]
    }
   ],
   "source": [
    "# load mnist dataset\n",
    "# Generate mnist data for localization\n",
    "(train_images, train_cls_true, train_reg_true), (test_images, test_cls_true, test_reg_true) = \\\n",
    "    mnist_localization_generator((231, 231), (231, 231),\n",
    "                                 background=True, \n",
    "                                 image_size_range=(60, 80),\n",
    "                                 image_ratio_range=(0.5, 1.5),\n",
    "                                 n_sample=1000)\n",
    "\n",
    "print(train_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8-wvV3c4sEsj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100, 1, 1, 11), (1100, 1, 1, 4), (1100, 1, 1, 15))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reg_cls = np.concatenate([train_reg_true, train_cls_true], axis=-1)\n",
    "train_cls_true.shape, train_reg_true.shape, train_reg_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VUwKAt9Zpxxz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 231, 231, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Fully convolution NN\n",
    "input_ = Input(shape=(231, 231, 1))\n",
    "print(input_)\n",
    "\n",
    "# Conv stage 1\n",
    "conv_1 = Conv2D(filters=96/8, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(input_)\n",
    "maxp_1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_1)\n",
    "\n",
    "# Conv stage 2\n",
    "conv_2 = Conv2D(filters=256/8, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_1)\n",
    "maxp_2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_2)\n",
    "\n",
    "# Conv stage 3\n",
    "conv_3 = Conv2D(filters=512/8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_2)\n",
    "\n",
    "# Conv stage 4\n",
    "conv_4 = Conv2D(filters=1024/8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_3)\n",
    "\n",
    "# Conv stage 5\n",
    "conv_5 = Conv2D(filters=1024/8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_4)\n",
    "maxp_5 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QtJLnycdq7EJ"
   },
   "outputs": [],
   "source": [
    "# loc header 1\n",
    "conv_6 = Conv2D(filters=4096/8, kernel_size=(6, 6), strides=(1, 1), padding='valid', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_5)\n",
    "\n",
    "# loc header 2\n",
    "conv_7 = Conv2D(filters=1024/8, kernel_size=(1, 1), strides=(1, 1), padding='valid', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_6)\n",
    "\n",
    "# loc header 3\n",
    "loc_output = Conv2D(filters=4, kernel_size=(1, 1), strides=(1, 1), padding='valid')(conv_7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KOpYA_ynq6ex"
   },
   "outputs": [],
   "source": [
    "\n",
    "# cls header 1\n",
    "conv_6 = Conv2D(filters=4096/8, kernel_size=(6, 6), strides=(1, 1), padding='valid', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_5)\n",
    "\n",
    "# cls header 2\n",
    "conv_7 = Conv2D(filters=1024/8, kernel_size=(1, 1), strides=(1, 1), padding='valid', activation='relu',\n",
    "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_6)\n",
    "\n",
    "# cls header 3\n",
    "cls_output = Conv2D(filters=11, kernel_size=(1, 1), strides=(1, 1), padding='valid', activation='softmax')(conv_7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VXXFr3QUwlIH"
   },
   "outputs": [],
   "source": [
    "output = Concatenate(axis=-1)([loc_output, cls_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5m4wsWOmsvkU"
   },
   "outputs": [],
   "source": [
    "def overfeat_mse(true, pred):\n",
    "    \"\"\"\n",
    "    :param true: ndarray, 4d tensor (NHWC) 단 C=4\n",
    "    :param pred: ndarray or tensor, 4d tensor (NHWC), 단 C=4\n",
    "    :return: mse_, float,\n",
    "    \"\"\"\n",
    "\n",
    "    # slicing classification and regression\n",
    "    mse = MSE(true, pred)\n",
    "    mse_ = tf.math.reduce_mean(mse)\n",
    "\n",
    "    return mse_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "j_1o1uYVu7Cw"
   },
   "outputs": [],
   "source": [
    "def overfeat_cee(true, pred):\n",
    "    \"\"\"\n",
    "    :param true: ndarray, 4d tensor (NHWC) 단 C=11\n",
    "    :param pred: ndarray or tensor, 4d tensor (NHWC), 단 C=11\n",
    "    :return: cee_, float,\n",
    "    \"\"\"\n",
    "\n",
    "    cee = CategoricalCrossentropy()\n",
    "    cee_ = cee(true, pred)\n",
    "\n",
    "    return cee_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vmwSeHbXr3bv"
   },
   "outputs": [],
   "source": [
    "def overfeat_loss(true, pred):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    :param true: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
    "    :param pred: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
    "    \"\"\"\n",
    "\n",
    "    true_reg = true[:, :, :, :4]\n",
    "    true_cls = true[:, :, :, 4:]\n",
    "\n",
    "    pred_reg = pred[:, :, :, :4]\n",
    "    pred_cls = pred[:, :, :, 4:]\n",
    "\n",
    "    # positive 인 data의 loss 만 localization loss 에 추가 \n",
    "    pos_mask = true_cls[:, :, :, -1] != 1   \n",
    "    pos_true_reg = true_reg[pos_mask]\n",
    "    pos_pred_reg = pred_reg[pos_mask]\n",
    "\n",
    "    mse_loss = overfeat_mse(pos_true_reg, pos_pred_reg)\n",
    "    cee_loss = overfeat_cee(true_cls, pred_cls)\n",
    "\n",
    "    total_loss = mse_loss*0.01 + cee_loss*2\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eOvVylAfw_B_"
   },
   "outputs": [],
   "source": [
    "def metric_mse(true, pred):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    :param true: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
    "    :param pred: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
    "    \"\"\"\n",
    "\n",
    "    true_reg = true[:, :, :, :4]\n",
    "    true_cls = true[:, :, :, 4:]\n",
    "    pred_cls = pred[:, :, :, 4:]\n",
    "    pred_reg = pred[:, :, :, :4]\n",
    "\n",
    "    # positive 인 data의 loss 만 localization loss 에 추가 \n",
    "    pos_mask = true_cls[:, :, :, -1] != 1   \n",
    "    pos_true_reg = true_reg[pos_mask]\n",
    "    pos_pred_reg = pred_reg[pos_mask]\n",
    "\n",
    "    mse_loss = overfeat_mse(pos_true_reg, pos_pred_reg)\n",
    "    return mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i-XPioEpw-am"
   },
   "outputs": [],
   "source": [
    "def metric_cee(true, pred):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    :param true: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
    "    :param pred: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
    "    \"\"\"\n",
    "    true_cls = true[:, :, :, 4:]\n",
    "    pred_cls = pred[:, :, :, 4:]\n",
    "    cee_loss = overfeat_cee(true_cls, pred_cls)\n",
    "\n",
    "    return cee_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zUuxjMdWrgM7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 231, 231, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 56, 12)   1464        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 12)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 32)   9632        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 12, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 12, 128)  73856       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 12, 128)  147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 128)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 512)    2359808     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 512)    2359808     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 1, 1, 128)    65664       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1, 1, 128)    65664       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 1, 1, 4)      516         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 11)     1419        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 1, 15)     0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,103,911\n",
      "Trainable params: 5,103,911\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generate keras model\n",
    "model = Model(input_, output)\n",
    "model.compile(optimizer='adam', loss=overfeat_loss, metrics=[metric_mse, metric_cee])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTeAbUy5ziVK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 13s 303ms/step - loss: 34.7761 - metric_mse: 2947.7329 - metric_cee: 2.5101\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 10s 294ms/step - loss: 13.4731 - metric_mse: 872.5986 - metric_cee: 2.3651\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 11s 313ms/step - loss: 8.9573 - metric_mse: 424.8591 - metric_cee: 2.3653\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 10s 300ms/step - loss: 8.1285 - metric_mse: 338.2043 - metric_cee: 2.3556\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 6.9827 - metric_mse: 231.9439 - metric_cee: 2.3320\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 6.3732 - metric_mse: 181.5611 - metric_cee: 2.2767\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 11s 308ms/step - loss: 6.1163 - metric_mse: 167.1715 - metric_cee: 2.2191\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 11s 306ms/step - loss: 5.9134 - metric_mse: 157.3243 - metric_cee: 2.1711\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 11s 303ms/step - loss: 5.8058 - metric_mse: 149.8237 - metric_cee: 2.1528\n",
      "Epoch 10/100\n",
      "16/35 [============>.................] - ETA: 6s - loss: 5.7173 - metric_mse: 146.2037 - metric_cee: 2.1253"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_reg_cls, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkQFdUJm205o"
   },
   "outputs": [],
   "source": [
    "pred_loc_cls = model.predict(test_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDIlRyZT7Lro"
   },
   "outputs": [],
   "source": [
    "pred_loc = pred_loc_cls[:, ..., :4]\n",
    "pred_cls = pred_loc_cls[:, ..., 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYQ_wJBr7N-4"
   },
   "outputs": [],
   "source": [
    "pred_loc = np.squeeze(pred_loc)\n",
    "pred_cls = np.argmax(pred_cls, axis=-1)\n",
    "pred_cls = np.squeeze(pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WG-NiADe7ZdK"
   },
   "outputs": [],
   "source": [
    "pred_loc = xywh2xyxy(pred_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gi6j9tlF7ajH"
   },
   "outputs": [],
   "source": [
    "index = 5\n",
    "rected_image = draw_rectangle(test_images[index, ..., 0], pred_loc[index])\n",
    "print(pred_cls)\n",
    "plt.imshow(rected_image)\n",
    "plt.title(pred_cls[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3lJjCeE7dSB"
   },
   "outputs": [],
   "source": [
    "model.save('./best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBfoYdDeEXbj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "overfeat.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
